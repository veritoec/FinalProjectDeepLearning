{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lyricsGenBiLSTM-commented.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Lyrics Generation with BiLSTM\n","Veronica Bruno(230904), Cristina Galvez (230260) and Rafael Bardisa (231142)"],"metadata":{"id":"VWgAenKe3XxV"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJ8fwjF9-d3o","outputId":"a25503c3-804e-451c-bc9c-b42c1a9d8b77","executionInfo":{"status":"ok","timestamp":1655210286533,"user_tz":-120,"elapsed":57050,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# import Keras library\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Activation, Dropout\n","from keras.layers import LSTM, Input, Bidirectional\n","from keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping\n","from keras.metrics import categorical_accuracy\n","\n","# import spacy, and spacy french model\n","# spacy is used to work on text\n","import spacy\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","#import other libraries\n","import numpy as np\n","import pandas as pd\n","import random\n","import sys\n","import os\n","import time\n","import codecs\n","import collections\n","from six.moves import cPickle\n","\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","data_path = '/content/drive/Shareddrives/Deep Learning/DeepLearning_2022/Final Project/Data/'\n","\n","df = pd.read_csv(data_path + 'songdata.csv')"]},{"cell_type":"markdown","source":["### Data Preparation\n","\n","Prepare all data from the dataset *'songdata.csv'* to be used in the BiLSTM algorithm."],"metadata":{"id":"guB0c0ax4BmK"}},{"cell_type":"code","source":["# join all song lyrics from the dataset in a long string\n","data = ', '.join(df['text'])"],"metadata":{"id":"Gt1m167vJeTI","executionInfo":{"status":"ok","timestamp":1655210286536,"user_tz":-120,"elapsed":21,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# function to create a wordlist\n","def create_wordlist(doc):\n","    wl = []\n","    for word in doc:\n","        if word.text not in (\"\\n\",\"\\n\\n\",'\\u2009','\\xa0'):\n","            wl.append(word.text.lower())\n","    return wl"],"metadata":{"id":"F89hFuE8OSeb","executionInfo":{"status":"ok","timestamp":1655210286538,"user_tz":-120,"elapsed":19,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# create array of words (in order)\n","wordlist = []\n","word_limit = 100000 # define amount of words used (limited by RAM memory)\n","\n","doc = nlp(data[0:word_limit])\n","wl = create_wordlist(doc)\n","wordlist = wordlist + wl"],"metadata":{"id":"QbyhvtApHfIY","executionInfo":{"status":"ok","timestamp":1655210289616,"user_tz":-120,"elapsed":3096,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["results_path = '/content/drive/Shareddrives/Deep Learning/DeepLearning_2022/Final Project/Results/'\n","\n","# count the number of words\n","word_counts = collections.Counter(wordlist)\n","\n","# Mapping from index to word : that's the vocabulary\n","vocabulary_inv = [x[0] for x in word_counts.most_common()]\n","vocabulary_inv = list(sorted(vocabulary_inv))\n","\n","# Mapping from word to index\n","vocab = {x: i for i, x in enumerate(vocabulary_inv)}\n","words = [x[0] for x in word_counts.most_common()]\n","\n","# size of the vocabulary\n","vocab_size = len(words)\n","print(\"Vocabulary size:\", vocab_size)\n","\n","# save the words and vocabulary\n","with open(results_path + \"vocab_file.pkl\", 'w+b') as f:\n","    cPickle.dump((words, vocab, vocabulary_inv), f)"],"metadata":{"id":"tBZO0DiCHm9f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cfe0424e-c9f2-470f-fa57-eb41b8810b61","executionInfo":{"status":"ok","timestamp":1655210290194,"user_tz":-120,"elapsed":586,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary size: 1832\n"]}]},{"cell_type":"code","source":["# create sequences of fixed length\n","sequences = []\n","next_words = []\n","seq_length = 30  # define sequence length\n","sequences_step = 1\n","\n","for i in range(0, len(wordlist) - seq_length, sequences_step):\n","    sequences.append(wordlist[i: i + seq_length])\n","    next_words.append(wordlist[i + seq_length])\n","\n","print('Number of sequences:', len(sequences))"],"metadata":{"id":"t5aEkfx6HpQC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d13fb2cf-0ca5-4d29-f3a5-bad7c04844ba","executionInfo":{"status":"ok","timestamp":1655210290195,"user_tz":-120,"elapsed":17,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of sequences: 24326\n"]}]},{"cell_type":"code","source":["# define data as matrices with 0s and 1s\n","X = np.zeros((len(sequences), seq_length, vocab_size), dtype=np.bool)\n","y = np.zeros((len(sequences), vocab_size), dtype=np.bool)\n","for i, sentence in enumerate(sequences):\n","    for t, word in enumerate(sentence):\n","        X[i, t, vocab[word]] = 1\n","    y[i, vocab[next_words[i]]] = 1"],"metadata":{"id":"8S_gvIAXHr0c","colab":{"base_uri":"https://localhost:8080/"},"outputId":"af81fe4a-cd18-411d-f222-d2ebe16ee03c","executionInfo":{"status":"ok","timestamp":1655210290621,"user_tz":-120,"elapsed":439,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]}]},{"cell_type":"markdown","source":["## Bidirectional LSTM Model"],"metadata":{"id":"fEButMW36NqM"}},{"cell_type":"code","source":["def bidirectional_lstm_model(seq_length, vocab_size):\n","    print('Build LSTM model.')\n","    model = Sequential()\n","    model.add(Bidirectional(LSTM(rnn_size, activation=\"relu\"),input_shape=(seq_length, vocab_size)))\n","    model.add(Dropout(0.6))\n","    model.add(Dense(vocab_size))\n","    model.add(Activation('softmax'))\n","    \n","    optimizer = Adam(lr=learning_rate)\n","    callbacks=[EarlyStopping(patience=2, monitor='val_loss')]\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[categorical_accuracy])\n","    print(\"model built!\")\n","    return model"],"metadata":{"id":"GeyDjz8vHuMU","executionInfo":{"status":"ok","timestamp":1655210290623,"user_tz":-120,"elapsed":9,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["rnn_size = 256 # size of RNN\n","learning_rate = 0.001 #learning rate\n","\n","md = bidirectional_lstm_model(seq_length, vocab_size)\n","md.summary()"],"metadata":{"id":"1M3-3P-WHxXr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"82842cac-d77b-423f-f1c2-1f8f18d4bcef","executionInfo":{"status":"ok","timestamp":1655210296029,"user_tz":-120,"elapsed":5414,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Build LSTM model.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","model built!\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," bidirectional (Bidirectiona  (None, 512)              4278272   \n"," l)                                                              \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 1832)              939816    \n","                                                                 \n"," activation (Activation)     (None, 1832)              0         \n","                                                                 \n","=================================================================\n","Total params: 5,218,088\n","Trainable params: 5,218,088\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"markdown","source":["## Training the Model"],"metadata":{"id":"6TLjp1587FjY"}},{"cell_type":"code","source":["batch_size = 32 # minibatch size\n","num_epochs = 50 # number of epochs\n","\n","callbacks=[EarlyStopping(patience=5, monitor='loss', restore_best_weights=True),\n","           ModelCheckpoint(filepath=results_path + 'my_model_gen_sentences.{epoch:02d}-{val_loss:.2f}.hdf5',\\\n","                           monitor='val_loss', verbose=0, mode='auto', period=2)]\n","# fit the model\n","history = md.fit(X, y,\n","                 batch_size=batch_size,\n","                 shuffle=True,\n","                 epochs=num_epochs,\n","                 #callbacks=callbacks,   # removed: Early Stopping\n","                 validation_split=0.1)\n","\n","# save the model\n","md.save(results_path + 'my_model_generate_sentences.h5')"],"metadata":{"id":"2BDRtgOwHzkJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b2f77709-b811-46df-b93a-d1c2a069125e","executionInfo":{"status":"ok","timestamp":1655214009949,"user_tz":-120,"elapsed":3713935,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/50\n","685/685 [==============================] - 80s 110ms/step - loss: 5.9352 - categorical_accuracy: 0.0856 - val_loss: 5.5943 - val_categorical_accuracy: 0.1628\n","Epoch 2/50\n","685/685 [==============================] - 75s 110ms/step - loss: 5.2069 - categorical_accuracy: 0.1054 - val_loss: 5.6476 - val_categorical_accuracy: 0.1611\n","Epoch 3/50\n","685/685 [==============================] - 74s 108ms/step - loss: 4.8601 - categorical_accuracy: 0.1345 - val_loss: 5.7079 - val_categorical_accuracy: 0.1336\n","Epoch 4/50\n","685/685 [==============================] - 74s 107ms/step - loss: 4.4258 - categorical_accuracy: 0.1800 - val_loss: 5.5996 - val_categorical_accuracy: 0.1562\n","Epoch 5/50\n","685/685 [==============================] - 74s 108ms/step - loss: 3.9890 - categorical_accuracy: 0.2320 - val_loss: 5.6967 - val_categorical_accuracy: 0.1747\n","Epoch 6/50\n","685/685 [==============================] - 75s 110ms/step - loss: 3.5819 - categorical_accuracy: 0.2848 - val_loss: 5.5710 - val_categorical_accuracy: 0.1932\n","Epoch 7/50\n","685/685 [==============================] - 74s 108ms/step - loss: 3.2238 - categorical_accuracy: 0.3338 - val_loss: 5.6929 - val_categorical_accuracy: 0.1771\n","Epoch 8/50\n","685/685 [==============================] - 74s 108ms/step - loss: 2.8914 - categorical_accuracy: 0.3886 - val_loss: 5.9236 - val_categorical_accuracy: 0.1924\n","Epoch 9/50\n","685/685 [==============================] - 74s 108ms/step - loss: 2.6256 - categorical_accuracy: 0.4290 - val_loss: 5.9442 - val_categorical_accuracy: 0.1940\n","Epoch 10/50\n","685/685 [==============================] - 75s 110ms/step - loss: 2.3773 - categorical_accuracy: 0.4763 - val_loss: 6.3144 - val_categorical_accuracy: 0.1841\n","Epoch 11/50\n","685/685 [==============================] - 74s 108ms/step - loss: 2.1528 - categorical_accuracy: 0.5125 - val_loss: 6.1875 - val_categorical_accuracy: 0.2051\n","Epoch 12/50\n","685/685 [==============================] - 73s 107ms/step - loss: 1.9695 - categorical_accuracy: 0.5426 - val_loss: 6.1915 - val_categorical_accuracy: 0.2100\n","Epoch 13/50\n","685/685 [==============================] - 74s 108ms/step - loss: 1.7958 - categorical_accuracy: 0.5797 - val_loss: 6.1024 - val_categorical_accuracy: 0.2158\n","Epoch 14/50\n","685/685 [==============================] - 75s 110ms/step - loss: 1.6238 - categorical_accuracy: 0.6115 - val_loss: 6.4316 - val_categorical_accuracy: 0.2096\n","Epoch 15/50\n","685/685 [==============================] - 73s 107ms/step - loss: 1.4937 - categorical_accuracy: 0.6364 - val_loss: 6.6257 - val_categorical_accuracy: 0.1981\n","Epoch 16/50\n","685/685 [==============================] - 73s 107ms/step - loss: 1.3710 - categorical_accuracy: 0.6598 - val_loss: 6.7479 - val_categorical_accuracy: 0.2121\n","Epoch 17/50\n","685/685 [==============================] - 74s 108ms/step - loss: 1.2363 - categorical_accuracy: 0.6913 - val_loss: 6.6675 - val_categorical_accuracy: 0.2178\n","Epoch 18/50\n","685/685 [==============================] - 76s 111ms/step - loss: 1.1573 - categorical_accuracy: 0.7063 - val_loss: 6.8199 - val_categorical_accuracy: 0.2203\n","Epoch 19/50\n","685/685 [==============================] - 74s 108ms/step - loss: 1.0363 - categorical_accuracy: 0.7270 - val_loss: 7.3124 - val_categorical_accuracy: 0.2076\n","Epoch 20/50\n","685/685 [==============================] - 74s 108ms/step - loss: 0.9403 - categorical_accuracy: 0.7536 - val_loss: 7.1311 - val_categorical_accuracy: 0.2129\n","Epoch 21/50\n","685/685 [==============================] - 74s 108ms/step - loss: 0.8615 - categorical_accuracy: 0.7733 - val_loss: 7.4859 - val_categorical_accuracy: 0.2088\n","Epoch 22/50\n","685/685 [==============================] - 74s 108ms/step - loss: 0.7751 - categorical_accuracy: 0.7925 - val_loss: 7.1549 - val_categorical_accuracy: 0.2117\n","Epoch 23/50\n","685/685 [==============================] - 75s 109ms/step - loss: 0.7297 - categorical_accuracy: 0.8046 - val_loss: 7.7759 - val_categorical_accuracy: 0.2030\n","Epoch 24/50\n","685/685 [==============================] - 76s 110ms/step - loss: 0.6563 - categorical_accuracy: 0.8242 - val_loss: 7.6015 - val_categorical_accuracy: 0.1989\n","Epoch 25/50\n","685/685 [==============================] - 74s 108ms/step - loss: 0.6101 - categorical_accuracy: 0.8339 - val_loss: 8.3913 - val_categorical_accuracy: 0.2096\n","Epoch 26/50\n","685/685 [==============================] - 73s 107ms/step - loss: 0.5697 - categorical_accuracy: 0.8448 - val_loss: 8.3798 - val_categorical_accuracy: 0.2104\n","Epoch 27/50\n","685/685 [==============================] - 75s 110ms/step - loss: 0.5281 - categorical_accuracy: 0.8565 - val_loss: 8.3705 - val_categorical_accuracy: 0.2154\n","Epoch 28/50\n","685/685 [==============================] - 74s 108ms/step - loss: 0.5356 - categorical_accuracy: 0.8535 - val_loss: 8.5929 - val_categorical_accuracy: 0.2100\n","Epoch 29/50\n","685/685 [==============================] - 75s 109ms/step - loss: 0.4536 - categorical_accuracy: 0.8719 - val_loss: 9.1558 - val_categorical_accuracy: 0.2039\n","Epoch 30/50\n","685/685 [==============================] - 74s 108ms/step - loss: 0.4210 - categorical_accuracy: 0.8852 - val_loss: 8.3315 - val_categorical_accuracy: 0.2010\n","Epoch 31/50\n","685/685 [==============================] - 75s 110ms/step - loss: 0.3991 - categorical_accuracy: 0.8893 - val_loss: 8.6406 - val_categorical_accuracy: 0.2030\n","Epoch 32/50\n","685/685 [==============================] - 74s 108ms/step - loss: 0.3779 - categorical_accuracy: 0.8945 - val_loss: 8.4963 - val_categorical_accuracy: 0.2199\n","Epoch 33/50\n","685/685 [==============================] - 74s 108ms/step - loss: 0.3515 - categorical_accuracy: 0.9003 - val_loss: 9.2291 - val_categorical_accuracy: 0.2080\n","Epoch 34/50\n","685/685 [==============================] - 74s 108ms/step - loss: 0.3449 - categorical_accuracy: 0.9054 - val_loss: 8.3593 - val_categorical_accuracy: 0.2170\n","Epoch 35/50\n","685/685 [==============================] - 75s 110ms/step - loss: 0.3351 - categorical_accuracy: 0.9063 - val_loss: 8.9497 - val_categorical_accuracy: 0.2215\n","Epoch 36/50\n","685/685 [==============================] - 74s 108ms/step - loss: 0.2975 - categorical_accuracy: 0.9161 - val_loss: 8.7561 - val_categorical_accuracy: 0.2088\n","Epoch 37/50\n","685/685 [==============================] - 74s 108ms/step - loss: 0.2787 - categorical_accuracy: 0.9223 - val_loss: 8.5587 - val_categorical_accuracy: 0.2236\n","Epoch 38/50\n","685/685 [==============================] - 74s 108ms/step - loss: 0.2694 - categorical_accuracy: 0.9268 - val_loss: 9.0334 - val_categorical_accuracy: 0.2035\n","Epoch 39/50\n","685/685 [==============================] - 75s 110ms/step - loss: 0.2575 - categorical_accuracy: 0.9282 - val_loss: 9.2487 - val_categorical_accuracy: 0.2211\n","Epoch 40/50\n","685/685 [==============================] - 74s 108ms/step - loss: 0.2444 - categorical_accuracy: 0.9321 - val_loss: 8.9481 - val_categorical_accuracy: 0.1989\n","Epoch 41/50\n","685/685 [==============================] - 74s 108ms/step - loss: 0.2596 - categorical_accuracy: 0.9292 - val_loss: 9.2159 - val_categorical_accuracy: 0.2072\n","Epoch 42/50\n","685/685 [==============================] - 73s 107ms/step - loss: 0.2653 - categorical_accuracy: 0.9284 - val_loss: 8.9383 - val_categorical_accuracy: 0.2063\n","Epoch 43/50\n","685/685 [==============================] - 75s 109ms/step - loss: 0.2047 - categorical_accuracy: 0.9406 - val_loss: 9.1580 - val_categorical_accuracy: 0.1989\n","Epoch 44/50\n","685/685 [==============================] - 74s 107ms/step - loss: 0.2050 - categorical_accuracy: 0.9428 - val_loss: 9.1202 - val_categorical_accuracy: 0.1977\n","Epoch 45/50\n","685/685 [==============================] - 73s 107ms/step - loss: 0.1882 - categorical_accuracy: 0.9471 - val_loss: 8.8569 - val_categorical_accuracy: 0.1969\n","Epoch 46/50\n","685/685 [==============================] - 73s 106ms/step - loss: 0.1928 - categorical_accuracy: 0.9455 - val_loss: 9.0254 - val_categorical_accuracy: 0.1985\n","Epoch 47/50\n","685/685 [==============================] - 73s 106ms/step - loss: 0.1831 - categorical_accuracy: 0.9464 - val_loss: 9.4448 - val_categorical_accuracy: 0.1989\n","Epoch 48/50\n","685/685 [==============================] - 74s 108ms/step - loss: 0.1783 - categorical_accuracy: 0.9513 - val_loss: 8.9257 - val_categorical_accuracy: 0.2030\n","Epoch 49/50\n","685/685 [==============================] - 73s 106ms/step - loss: 0.1717 - categorical_accuracy: 0.9520 - val_loss: 8.8621 - val_categorical_accuracy: 0.2158\n","Epoch 50/50\n","685/685 [==============================] - 73s 106ms/step - loss: 0.1829 - categorical_accuracy: 0.9487 - val_loss: 8.9002 - val_categorical_accuracy: 0.2096\n"]}]},{"cell_type":"markdown","source":["## Upload Generated Data"],"metadata":{"id":"fTM8aDzT8ftC"}},{"cell_type":"code","source":["#load vocabulary\n","print(\"loading vocabulary...\")\n","vocab_file = os.path.join(results_path, \"vocab_file.pkl\")\n","\n","with open(os.path.join(results_path, 'vocab_file.pkl'), 'rb') as f:\n","        words, vocab, vocabulary_inv = cPickle.load(f)\n","\n","vocab_size = len(words)\n","\n","from keras.models import load_model\n","\n","# load the model\n","print(\"loading model...\")\n","model = load_model(results_path + 'my_model_generate_sentences.h5')"],"metadata":{"id":"Wr7FAoomH2D8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8397a5e4-5398-4145-bdf8-4157ab411738","executionInfo":{"status":"ok","timestamp":1655214010767,"user_tz":-120,"elapsed":827,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["loading vocabulary...\n","loading model...\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}]},{"cell_type":"markdown","source":["## Generate Lyrics"],"metadata":{"id":"9oHA2APF8sBN"}},{"cell_type":"code","source":["def sample(preds, temperature=1.0):\n","    # helper function to sample an index from a probability array\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)"],"metadata":{"id":"8qT9RjAzH4AN","executionInfo":{"status":"ok","timestamp":1655214010768,"user_tz":-120,"elapsed":6,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["words_number = 300 # number of words to generate\n","seed_sentences = \"and one and two and one two five let 's go together to party out loud come with me to the sun\" # seed sentence to start the generating.\n","\n","# initiate sentences\n","generated = ''\n","sentence = []\n","\n","#we shate the seed accordingly to the neural netwrok needs:\n","for i in range (seq_length):\n","    sentence.append(\"oh\")\n","\n","seed = seed_sentences.split()\n","\n","for i in range(len(seed)):\n","    sentence[seq_length-i-1]=seed[len(seed)-i-1]\n","\n","generated += ' '.join(sentence)\n","\n","#then, we generate the text\n","for i in range(words_number):\n","    # create the vector\n","    x = np.zeros((1, seq_length, vocab_size))\n","    for t, word in enumerate(sentence):\n","      x[0, t, vocab[word]] = 1.\n","\n","    # calculate next word\n","    preds = model.predict(x, verbose=0)[0]\n","    next_index = sample(preds, 0.33)\n","    next_word = vocabulary_inv[next_index]\n","\n","    # add the next word to the text\n","    generated += \" \" + next_word\n","    # shift the sentence by one, and and the next word at its end\n","    sentence = sentence[1:] + [next_word]\n","\n","# print the whole text\n","print('\\n' + generated)"],"metadata":{"id":"5UFN7pqpH-nv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3f5a715a-ae23-4672-b1ac-d49912c9909c","executionInfo":{"status":"ok","timestamp":1655214024826,"user_tz":-120,"elapsed":14063,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n","  after removing the cwd from sys.path.\n"]},{"output_type":"stream","name":"stdout","text":["\n","oh oh oh oh oh oh oh oh and one and two and one two five let 's go together to party out loud come with me to the sun i still still  \n"," never on your music , with me with your feelings  \n"," merry - go - round  \n"," where am i bound  \n"," with the love it with your feelings  \n"," merry - go - round  \n","  \n"," who wants to kiss me  \n"," and hug me and miss me  \n"," yes , who wants to do it  \n"," i wish that i knew it  \n","  \n"," merry - go - round  \n"," wish i had found  \n"," somebody to care for  \n"," where am i bound  \n","  \n"," life is so lonely  \n"," if life is just only  \n"," to love with my loving  \n"," goes round and round  \n","  \n"," looking for someone  \n"," who would want to stay  \n"," i might find her  \n"," with a bit of luck one day  \n","  \n"," but who knows  \n"," so until then  \n"," i can only try and try again  \n","  \n"," merry - go - round  \n"," where am i bound  \n"," with my love and feelings  \n"," merry - go - round  \n","  \n"," who wants to kiss me  \n"," and hug me and miss me  \n"," yes , who wants to do it  \n"," i wish that i knew it  \n","  \n"," merry - go - round  \n"," wish i had found  \n"," somebody to care for  \n"," where am i bound  \n","  \n"," life is so lonely  \n"," if life is just only  \n"," to love with my loving  \n"," goes round and round  \n","  \n"," merry - go - round  \n"," where am i bound  \n"," with my love and feelings  \n"," merry - go - round  \n","  \n"," who wants to kiss me  \n"," and hug me and miss me  \n"," yes , who wants to do it  \n"," i wish that i knew it  \n","  \n"," merry - go - round\n"]}]}]}