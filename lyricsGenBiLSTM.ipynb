{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lyricsGenBiLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ8fwjF9-d3o",
        "outputId": "d10ac7ad-029c-4b24-f42b-778c1c3e9f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "#import Keras library\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers import LSTM, Input, Bidirectional\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.metrics import categorical_accuracy\n",
        "\n",
        "#import spacy, and spacy french model\n",
        "# spacy is used to work on text\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "#import other libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import codecs\n",
        "import collections\n",
        "from six.moves import cPickle\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/Shareddrives/Deep Learning/DeepLearning_2022/Final Project/Data/'\n",
        "\n",
        "df = pd.read_csv(data_path + 'songdata.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = ', '.join(df['text'])"
      ],
      "metadata": {
        "id": "Gt1m167vJeTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_wordlist(doc):\n",
        "    wl = []\n",
        "    for word in doc:\n",
        "        if word.text not in (\"\\n\",\"\\n\\n\",'\\u2009','\\xa0'):\n",
        "            wl.append(word.text.lower())\n",
        "    return wl"
      ],
      "metadata": {
        "id": "F89hFuE8OSeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordlist = []\n",
        "\n",
        "#create sentences\n",
        "doc = nlp(data[0:100000])\n",
        "wl = create_wordlist(doc)\n",
        "wordlist = wordlist + wl"
      ],
      "metadata": {
        "id": "QbyhvtApHfIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_path = '/content/drive/Shareddrives/Deep Learning/DeepLearning_2022/Final Project/Results/'\n",
        "\n",
        "# count the number of words\n",
        "word_counts = collections.Counter(wordlist)\n",
        "\n",
        "# Mapping from index to word : that's the vocabulary\n",
        "vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
        "vocabulary_inv = list(sorted(vocabulary_inv))\n",
        "\n",
        "# Mapping from word to index\n",
        "vocab = {x: i for i, x in enumerate(vocabulary_inv)}\n",
        "words = [x[0] for x in word_counts.most_common()]\n",
        "\n",
        "#size of the vocabulary\n",
        "vocab_size = len(words)\n",
        "print(\"vocab size: \", vocab_size)\n",
        "\n",
        "#save the words and vocabulary\n",
        "with open(results_path + \"vocab_file.pkl\", 'w+b') as f:\n",
        "    cPickle.dump((words, vocab, vocabulary_inv), f)"
      ],
      "metadata": {
        "id": "tBZO0DiCHm9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b709705-f5ea-4894-c89a-6426dd85407b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size:  1832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create sequences\n",
        "sequences = []\n",
        "next_words = []\n",
        "seq_length = 30\n",
        "sequences_step = 1\n",
        "for i in range(0, len(wordlist) - seq_length, sequences_step):\n",
        "    sequences.append(wordlist[i: i + seq_length])\n",
        "    next_words.append(wordlist[i + seq_length])\n",
        "\n",
        "print('nb sequences:', len(sequences))"
      ],
      "metadata": {
        "id": "t5aEkfx6HpQC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e5c282e-6726-4b73-faad-cc6772044799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb sequences: 24326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sequences), seq_length, vocab_size), dtype=np.bool)\n",
        "y = np.zeros((len(sequences), vocab_size), dtype=np.bool)\n",
        "for i, sentence in enumerate(sequences):\n",
        "    for t, word in enumerate(sentence):\n",
        "        X[i, t, vocab[word]] = 1\n",
        "    y[i, vocab[next_words[i]]] = 1"
      ],
      "metadata": {
        "id": "8S_gvIAXHr0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6082c39-677f-4d76-9dc0-e35232366c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bidirectional_lstm_model(seq_length, vocab_size):\n",
        "    print('Build LSTM model.')\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(rnn_size, activation=\"relu\"),input_shape=(seq_length, vocab_size)))\n",
        "    model.add(Dropout(0.6))\n",
        "    model.add(Dense(vocab_size))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    optimizer = Adam(lr=learning_rate)\n",
        "    callbacks=[EarlyStopping(patience=2, monitor='val_loss')]\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[categorical_accuracy])\n",
        "    print(\"model built!\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "GeyDjz8vHuMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_size = 256 # size of RNN\n",
        "learning_rate = 0.001 #learning rate\n",
        "\n",
        "md = bidirectional_lstm_model(seq_length, vocab_size)\n",
        "md.summary()"
      ],
      "metadata": {
        "id": "1M3-3P-WHxXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "810f9a30-1ff9-46d4-97e2-32892606251e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build LSTM model.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "model built!\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 512)              4278272   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1832)              939816    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1832)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,218,088\n",
            "Trainable params: 5,218,088\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32 # minibatch size\n",
        "num_epochs = 50 # number of epochs\n",
        "\n",
        "callbacks=[EarlyStopping(patience=5, monitor='loss', restore_best_weights=True),\n",
        "           ModelCheckpoint(filepath=results_path + 'my_model_gen_sentences.{epoch:02d}-{val_loss:.2f}.hdf5',\\\n",
        "                           monitor='val_loss', verbose=0, mode='auto', period=2)]\n",
        "#fit the model\n",
        "history = md.fit(X, y,\n",
        "                 batch_size=batch_size,\n",
        "                 shuffle=True,\n",
        "                 epochs=num_epochs,\n",
        "                 #callbacks=callbacks,\n",
        "                 validation_split=0.1)\n",
        "\n",
        "#save the model\n",
        "md.save(results_path + 'my_model_generate_sentences.h5')"
      ],
      "metadata": {
        "id": "2BDRtgOwHzkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77312875-388b-47ea-a1be-b2a3566d0c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "685/685 [==============================] - 74s 102ms/step - loss: 6.1565 - categorical_accuracy: 0.0768 - val_loss: 5.7682 - val_categorical_accuracy: 0.1258\n",
            "Epoch 2/50\n",
            "685/685 [==============================] - 68s 100ms/step - loss: 5.4003 - categorical_accuracy: 0.0983 - val_loss: 5.6692 - val_categorical_accuracy: 0.1480\n",
            "Epoch 3/50\n",
            "685/685 [==============================] - 68s 100ms/step - loss: 5.1638 - categorical_accuracy: 0.1109 - val_loss: 5.6505 - val_categorical_accuracy: 0.1673\n",
            "Epoch 4/50\n",
            "685/685 [==============================] - 68s 99ms/step - loss: 4.8611 - categorical_accuracy: 0.1352 - val_loss: 5.6075 - val_categorical_accuracy: 0.1718\n",
            "Epoch 5/50\n",
            "685/685 [==============================] - 69s 101ms/step - loss: 4.5312 - categorical_accuracy: 0.1797 - val_loss: 5.6240 - val_categorical_accuracy: 0.1767\n",
            "Epoch 6/50\n",
            "685/685 [==============================] - 67s 99ms/step - loss: 4.0760 - categorical_accuracy: 0.2311 - val_loss: 5.6252 - val_categorical_accuracy: 0.1767\n",
            "Epoch 7/50\n",
            "685/685 [==============================] - 68s 100ms/step - loss: 3.6800 - categorical_accuracy: 0.2789 - val_loss: 5.7640 - val_categorical_accuracy: 0.1915\n",
            "Epoch 8/50\n",
            "685/685 [==============================] - 68s 99ms/step - loss: 3.3205 - categorical_accuracy: 0.3269 - val_loss: 5.8025 - val_categorical_accuracy: 0.1854\n",
            "Epoch 9/50\n",
            "685/685 [==============================] - 68s 99ms/step - loss: 2.9737 - categorical_accuracy: 0.3792 - val_loss: 5.6977 - val_categorical_accuracy: 0.1977\n",
            "Epoch 10/50\n",
            "685/685 [==============================] - 70s 102ms/step - loss: 2.6703 - categorical_accuracy: 0.4260 - val_loss: 5.8565 - val_categorical_accuracy: 0.1882\n",
            "Epoch 11/50\n",
            "685/685 [==============================] - 68s 99ms/step - loss: 2.3904 - categorical_accuracy: 0.4767 - val_loss: 5.8818 - val_categorical_accuracy: 0.1903\n",
            "Epoch 12/50\n",
            "685/685 [==============================] - 67s 98ms/step - loss: 2.1503 - categorical_accuracy: 0.5156 - val_loss: 5.8414 - val_categorical_accuracy: 0.1936\n",
            "Epoch 13/50\n",
            "685/685 [==============================] - 68s 99ms/step - loss: 1.9437 - categorical_accuracy: 0.5541 - val_loss: 5.9328 - val_categorical_accuracy: 0.1866\n",
            "Epoch 14/50\n",
            "685/685 [==============================] - 69s 101ms/step - loss: 1.7578 - categorical_accuracy: 0.5929 - val_loss: 6.1735 - val_categorical_accuracy: 0.2055\n",
            "Epoch 15/50\n",
            "685/685 [==============================] - 68s 100ms/step - loss: 1.6043 - categorical_accuracy: 0.6160 - val_loss: 6.1611 - val_categorical_accuracy: 0.1944\n",
            "Epoch 16/50\n",
            "685/685 [==============================] - 69s 100ms/step - loss: 1.4402 - categorical_accuracy: 0.6521 - val_loss: 6.2337 - val_categorical_accuracy: 0.1862\n",
            "Epoch 17/50\n",
            "685/685 [==============================] - 69s 100ms/step - loss: 1.3224 - categorical_accuracy: 0.6748 - val_loss: 6.2580 - val_categorical_accuracy: 0.1932\n",
            "Epoch 18/50\n",
            "685/685 [==============================] - 69s 101ms/step - loss: 1.2055 - categorical_accuracy: 0.6990 - val_loss: 6.2343 - val_categorical_accuracy: 0.1940\n",
            "Epoch 19/50\n",
            "685/685 [==============================] - 70s 103ms/step - loss: 1.0918 - categorical_accuracy: 0.7247 - val_loss: 6.1855 - val_categorical_accuracy: 0.1989\n",
            "Epoch 20/50\n",
            "685/685 [==============================] - 68s 99ms/step - loss: 0.9956 - categorical_accuracy: 0.7474 - val_loss: 6.4195 - val_categorical_accuracy: 0.2026\n",
            "Epoch 21/50\n",
            "685/685 [==============================] - 67s 98ms/step - loss: 0.9306 - categorical_accuracy: 0.7616 - val_loss: 6.3925 - val_categorical_accuracy: 0.1989\n",
            "Epoch 22/50\n",
            "685/685 [==============================] - 68s 99ms/step - loss: 0.8431 - categorical_accuracy: 0.7829 - val_loss: 6.5347 - val_categorical_accuracy: 0.2133\n",
            "Epoch 23/50\n",
            "685/685 [==============================] - 69s 101ms/step - loss: 0.7775 - categorical_accuracy: 0.7977 - val_loss: 6.4801 - val_categorical_accuracy: 0.2170\n",
            "Epoch 24/50\n",
            "685/685 [==============================] - 67s 98ms/step - loss: 0.7362 - categorical_accuracy: 0.8098 - val_loss: 6.5284 - val_categorical_accuracy: 0.2104\n",
            "Epoch 25/50\n",
            "685/685 [==============================] - 67s 98ms/step - loss: 0.6721 - categorical_accuracy: 0.8256 - val_loss: 6.5720 - val_categorical_accuracy: 0.2080\n",
            "Epoch 26/50\n",
            "685/685 [==============================] - 68s 99ms/step - loss: 0.6391 - categorical_accuracy: 0.8326 - val_loss: 6.5464 - val_categorical_accuracy: 0.2113\n",
            "Epoch 27/50\n",
            "685/685 [==============================] - 67s 98ms/step - loss: 0.5825 - categorical_accuracy: 0.8432 - val_loss: 6.6636 - val_categorical_accuracy: 0.2076\n",
            "Epoch 28/50\n",
            "685/685 [==============================] - 69s 100ms/step - loss: 0.5545 - categorical_accuracy: 0.8511 - val_loss: 6.7903 - val_categorical_accuracy: 0.2067\n",
            "Epoch 29/50\n",
            "685/685 [==============================] - 67s 98ms/step - loss: 0.5229 - categorical_accuracy: 0.8605 - val_loss: 6.6848 - val_categorical_accuracy: 0.2109\n",
            "Epoch 30/50\n",
            "685/685 [==============================] - 67s 98ms/step - loss: 0.4881 - categorical_accuracy: 0.8674 - val_loss: 6.8191 - val_categorical_accuracy: 0.2162\n",
            "Epoch 31/50\n",
            "685/685 [==============================] - 68s 99ms/step - loss: 0.4695 - categorical_accuracy: 0.8751 - val_loss: 7.0945 - val_categorical_accuracy: 0.2018\n",
            "Epoch 32/50\n",
            "685/685 [==============================] - 69s 101ms/step - loss: 0.4437 - categorical_accuracy: 0.8788 - val_loss: 6.8290 - val_categorical_accuracy: 0.2133\n",
            "Epoch 33/50\n",
            "685/685 [==============================] - 68s 100ms/step - loss: 0.4095 - categorical_accuracy: 0.8902 - val_loss: 6.9425 - val_categorical_accuracy: 0.2113\n",
            "Epoch 34/50\n",
            "685/685 [==============================] - 68s 99ms/step - loss: 0.3948 - categorical_accuracy: 0.8922 - val_loss: 7.0285 - val_categorical_accuracy: 0.1993\n",
            "Epoch 35/50\n",
            "685/685 [==============================] - 68s 100ms/step - loss: 0.3721 - categorical_accuracy: 0.8996 - val_loss: 6.9642 - val_categorical_accuracy: 0.2014\n",
            "Epoch 36/50\n",
            "685/685 [==============================] - 68s 100ms/step - loss: 0.3578 - categorical_accuracy: 0.9023 - val_loss: 6.9832 - val_categorical_accuracy: 0.2129\n",
            "Epoch 37/50\n",
            "685/685 [==============================] - 70s 102ms/step - loss: 0.3487 - categorical_accuracy: 0.9063 - val_loss: 7.0304 - val_categorical_accuracy: 0.1998\n",
            "Epoch 38/50\n",
            "685/685 [==============================] - 68s 99ms/step - loss: 0.3190 - categorical_accuracy: 0.9152 - val_loss: 7.0608 - val_categorical_accuracy: 0.2014\n",
            "Epoch 39/50\n",
            "685/685 [==============================] - 68s 100ms/step - loss: 0.3111 - categorical_accuracy: 0.9154 - val_loss: 7.1916 - val_categorical_accuracy: 0.1928\n",
            "Epoch 40/50\n",
            "685/685 [==============================] - 69s 100ms/step - loss: 0.3029 - categorical_accuracy: 0.9184 - val_loss: 7.0889 - val_categorical_accuracy: 0.2026\n",
            "Epoch 41/50\n",
            "685/685 [==============================] - 70s 102ms/step - loss: 0.2834 - categorical_accuracy: 0.9245 - val_loss: 7.3540 - val_categorical_accuracy: 0.1915\n",
            "Epoch 42/50\n",
            "685/685 [==============================] - 68s 100ms/step - loss: 0.2823 - categorical_accuracy: 0.9235 - val_loss: 7.0114 - val_categorical_accuracy: 0.2018\n",
            "Epoch 43/50\n",
            "685/685 [==============================] - 68s 99ms/step - loss: 0.2669 - categorical_accuracy: 0.9269 - val_loss: 7.2900 - val_categorical_accuracy: 0.2059\n",
            "Epoch 44/50\n",
            "685/685 [==============================] - 69s 101ms/step - loss: 0.2475 - categorical_accuracy: 0.9330 - val_loss: 7.2922 - val_categorical_accuracy: 0.2051\n",
            "Epoch 45/50\n",
            "685/685 [==============================] - 71s 103ms/step - loss: 0.2471 - categorical_accuracy: 0.9304 - val_loss: 7.2114 - val_categorical_accuracy: 0.2088\n",
            "Epoch 46/50\n",
            "685/685 [==============================] - 71s 104ms/step - loss: 0.2393 - categorical_accuracy: 0.9345 - val_loss: 7.3937 - val_categorical_accuracy: 0.2072\n",
            "Epoch 47/50\n",
            "685/685 [==============================] - 69s 100ms/step - loss: 0.2348 - categorical_accuracy: 0.9361 - val_loss: 7.2381 - val_categorical_accuracy: 0.2051\n",
            "Epoch 48/50\n",
            "685/685 [==============================] - 69s 101ms/step - loss: 0.2213 - categorical_accuracy: 0.9387 - val_loss: 7.2949 - val_categorical_accuracy: 0.1948\n",
            "Epoch 49/50\n",
            "685/685 [==============================] - 70s 102ms/step - loss: 0.2081 - categorical_accuracy: 0.9439 - val_loss: 7.5723 - val_categorical_accuracy: 0.2039\n",
            "Epoch 50/50\n",
            "685/685 [==============================] - 71s 104ms/step - loss: 0.2049 - categorical_accuracy: 0.9435 - val_loss: 7.3420 - val_categorical_accuracy: 0.2084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load vocabulary\n",
        "print(\"loading vocabulary...\")\n",
        "vocab_file = os.path.join(results_path, \"vocab_file.pkl\")\n",
        "\n",
        "with open(os.path.join(results_path, 'vocab_file.pkl'), 'rb') as f:\n",
        "        words, vocab, vocabulary_inv = cPickle.load(f)\n",
        "\n",
        "vocab_size = len(words)\n",
        "\n",
        "from keras.models import load_model\n",
        "# load the model\n",
        "print(\"loading model...\")\n",
        "model = load_model(results_path + 'my_model_generate_sentences.h5')"
      ],
      "metadata": {
        "id": "Wr7FAoomH2D8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac1570a-f3ee-4d16-86d9-0959c9a4dd33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading vocabulary...\n",
            "loading model...\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "8qT9RjAzH4AN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_number = 300 # number of words to generate\n",
        "seed_sentences = \"and one and two and one two five let 's go together to party out loud come with me to the sun\" #seed sentence to start the generating.\n",
        "\n",
        "#initiate sentences\n",
        "generated = ''\n",
        "sentence = []\n",
        "\n",
        "#we shate the seed accordingly to the neural netwrok needs:\n",
        "for i in range (seq_length):\n",
        "    sentence.append(\"oh\")\n",
        "\n",
        "seed = seed_sentences.split()\n",
        "\n",
        "for i in range(len(seed)):\n",
        "    sentence[seq_length-i-1]=seed[len(seed)-i-1]\n",
        "\n",
        "generated += ' '.join(sentence)\n",
        "\n",
        "#then, we generate the text\n",
        "for i in range(words_number):\n",
        "    #create the vector\n",
        "    x = np.zeros((1, seq_length, vocab_size))\n",
        "    for t, word in enumerate(sentence):\n",
        "      x[0, t, vocab[word]] = 1.\n",
        "\n",
        "    #calculate next word\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    next_index = sample(preds, 0.33)\n",
        "    next_word = vocabulary_inv[next_index]\n",
        "\n",
        "    #add the next word to the text\n",
        "    generated += \" \" + next_word\n",
        "    # shift the sentence by one, and and the next word at its end\n",
        "    sentence = sentence[1:] + [next_word]\n",
        "\n",
        "#print the whole text\n",
        "print(generated)"
      ],
      "metadata": {
        "id": "5UFN7pqpH-nv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "985cbc28-e56f-4baa-f429-022238f6181e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "oh oh oh oh oh oh oh oh and one and two and one two five let 's go together to party out loud come with me to the sun and i 'm leaving and i know what you do  \n",
            " i know i know just a dream , you 're gon na make me  \n",
            " make me sing , it 's a only bad , my love , you 're my loving  \n",
            " still you 're gon na sing it  \n",
            " you 'll be love song , gon na sing it for you , gon na give you sweet loving , gon na give myself too  \n",
            " gon na sing you my love song , when i think about you  \n",
            " you 're all i ever need , my darling  \n",
            " and i would love to sing my love song  \n",
            " for you , when the autumn leaves are falling to the ground  \n",
            " when the air gets cold then i think of us  \n",
            " of you and i  \n",
            " and it almost makes me cry  \n",
            " so sad and kind of bitter sweet  \n",
            " and the memories filled with tears  \n",
            " and i feel my heart will break  \n",
            " guess it all was my mistake  \n",
            "  \n",
            " autumn 's chilly winds were blowing through the trees  \n",
            " the rain fell softly on your face  \n",
            " oh i remember every little thing about that day  \n",
            " i remember every place  \n",
            " grey skies , you were laughing at the clouds  \n",
            " the rain fell softly on your face  \n",
            " the memories of our time together can not be replaced  \n",
            " i never loved you more than on those happy autumn days , agnetha , frida early this morning i drove in the rain  \n",
            " out to the airport to get on the plain  \n",
            " hey honolulu , i 'm going to happy hawaii  \n",
            " alice has been there , she said it was fun  \n",
            "  \n",
            " swimming and surfing , enjoying\n"
          ]
        }
      ]
    }
  ]
}