{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lyricsGenAll.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Lyrics Generation\n","**Veronica Bruno (230904), Cristina Galvez (230260) and Rafael Bardisa (231142)**\n","\n","In this notebook, we prepare a dataset containing the lyrics of many famous songs to feed different Deep Learning Models:\n","- RNN \n","- LSTM\n","- BiDirectional LSTM\n","\n","Once the model is trained, it is able to generate new song lyrics given a seed (an initial string of words) that will resemble the patterns the model will have learned during training."],"metadata":{"id":"VWgAenKe3XxV"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJ8fwjF9-d3o","outputId":"d5add2c9-5082-4fdc-8785-8344919ec183","executionInfo":{"status":"ok","timestamp":1655237709546,"user_tz":-120,"elapsed":7525,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# import Keras library\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Activation, Dropout\n","from keras.layers import LSTM, SimpleRNN, Input, Bidirectional\n","from keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping\n","from keras.metrics import categorical_accuracy\n","\n","# import spacy, and spacy french model\n","# spacy is used to work on text\n","import spacy\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","#import other libraries\n","import numpy as np\n","import pandas as pd\n","import random\n","import sys\n","import os\n","import time\n","import codecs\n","import collections\n","from six.moves import cPickle\n","\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","data_path = '/content/drive/Shareddrives/Deep Learning/DeepLearning_2022/Final Project/Data/'\n","results_path = '/content/drive/Shareddrives/Deep Learning/DeepLearning_2022/Final Project/Results/'\n","\n","df = pd.read_csv(data_path + 'songdata.csv')"]},{"cell_type":"markdown","source":["### Data Preparation\n","\n","Prepare all data from the dataset *'songdata.csv'* to be used in the BiLSTM algorithm."],"metadata":{"id":"guB0c0ax4BmK"}},{"cell_type":"code","source":["# join all song lyrics from the dataset in a long string\n","data = ', '.join(df['text'])"],"metadata":{"id":"Gt1m167vJeTI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function to create a wordlist\n","def create_wordlist(doc):\n","    wl = []\n","    for word in doc:\n","        if word.text not in (\"\\n\",\"\\n\\n\",'\\u2009','\\xa0'):\n","            wl.append(word.text.lower())\n","    return wl"],"metadata":{"id":"F89hFuE8OSeb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create array of words (in order)\n","wordlist = []\n","word_limit = 100000 # define amount of words used (limited by RAM memory)\n","\n","doc = nlp(data[0:word_limit])\n","wl = create_wordlist(doc)\n","wordlist = wordlist + wl"],"metadata":{"id":"QbyhvtApHfIY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# count the number of words\n","word_counts = collections.Counter(wordlist)\n","\n","# Mapping from index to word : that's the vocabulary\n","vocabulary_inv = [x[0] for x in word_counts.most_common()]\n","vocabulary_inv = list(sorted(vocabulary_inv))\n","\n","# Mapping from word to index\n","vocab = {x: i for i, x in enumerate(vocabulary_inv)}\n","words = [x[0] for x in word_counts.most_common()]\n","\n","# size of the vocabulary\n","vocab_size = len(words)\n","print(\"Vocabulary size:\", vocab_size)\n","\n","# save the words and vocabulary\n","with open(results_path + \"vocab_file.pkl\", 'w+b') as f:\n","    cPickle.dump((words, vocab, vocabulary_inv), f)"],"metadata":{"id":"tBZO0DiCHm9f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"539ba251-c8a3-446a-f7e8-abfa0dbe6a5f","executionInfo":{"status":"ok","timestamp":1655237743914,"user_tz":-120,"elapsed":9,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary size: 1832\n"]}]},{"cell_type":"code","source":["# create sequences of fixed length\n","sequences = []\n","next_words = []\n","seq_length = 30  # define sequence length\n","sequences_step = 1\n","\n","for i in range(0, len(wordlist) - seq_length, sequences_step):\n","    sequences.append(wordlist[i: i + seq_length])\n","    next_words.append(wordlist[i + seq_length])\n","\n","print('Number of sequences:', len(sequences))"],"metadata":{"id":"t5aEkfx6HpQC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ecd21d31-ad27-40d4-9b44-4af982cc8124","executionInfo":{"status":"ok","timestamp":1655237747966,"user_tz":-120,"elapsed":258,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of sequences: 24326\n"]}]},{"cell_type":"code","source":["# define data as matrices with 0s and 1s\n","X = np.zeros((len(sequences), seq_length, vocab_size), dtype=np.bool)\n","y = np.zeros((len(sequences), vocab_size), dtype=np.bool)\n","for i, sentence in enumerate(sequences):\n","    for t, word in enumerate(sentence):\n","        X[i, t, vocab[word]] = 1\n","    y[i, vocab[next_words[i]]] = 1"],"metadata":{"id":"8S_gvIAXHr0c","colab":{"base_uri":"https://localhost:8080/"},"outputId":"076f9ae0-f140-4fe6-c0c1-cc070a93a251","executionInfo":{"status":"ok","timestamp":1655237752432,"user_tz":-120,"elapsed":1054,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]}]},{"cell_type":"markdown","source":["## Model Definition"],"metadata":{"id":"fEButMW36NqM"}},{"cell_type":"markdown","source":["The first model we are going to define will be the **RNN** model:"],"metadata":{"id":"3Rr_lAbmF8fE"}},{"cell_type":"code","source":["def rnn_model(seq_length, vocab_size):\n","    print('Build RNN model.')\n","    model = Sequential()\n","    model.add(SimpleRNN(units, activation=\"relu\",input_shape=(seq_length, vocab_size))) # add RNN layer\n","    model.add(Dropout(0.6))\n","    model.add(Dense(vocab_size))\n","    model.add(Activation('softmax'))\n","    \n","    optimizer = Adam(lr=learning_rate)\n","    callbacks=[EarlyStopping(patience=2, monitor='val_loss')]\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[categorical_accuracy])\n","    print(\"model built!\")\n","    return model"],"metadata":{"id":"G5MecYPwqlh7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The following is the **LSTM** model:"],"metadata":{"id":"jNvar8OhGCIX"}},{"cell_type":"code","source":["def lstm_model(seq_length, vocab_size):\n","    print('Build LSTM model.')\n","    model = Sequential()\n","    model.add(LSTM(units, activation=\"relu\",input_shape=(seq_length, vocab_size))) # add LSTM layer\n","    model.add(Dropout(0.6))\n","    model.add(Dense(vocab_size))\n","    model.add(Activation('softmax'))\n","    \n","    optimizer = Adam(lr=learning_rate)\n","    callbacks=[EarlyStopping(patience=2, monitor='val_loss')]\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[categorical_accuracy])\n","    print(\"model built!\")\n","    return model"],"metadata":{"id":"GeyDjz8vHuMU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The following function defines a **Bidirectional LSTM** model, which uses two LSTM models (one in each direction) so that both directions of propagation are taken into account."],"metadata":{"id":"s-5DUwuLGIJ8"}},{"cell_type":"code","source":["def bidirectional_lstm_model(seq_length, vocab_size):\n","    print('Build LSTM model.')\n","    model = Sequential()\n","    model.add(Bidirectional(LSTM(units, activation=\"relu\"),input_shape=(seq_length, vocab_size))) # add BiLSTM layer\n","    model.add(Dropout(0.6))\n","    model.add(Dense(vocab_size))\n","    model.add(Activation('softmax'))\n","    \n","    optimizer = Adam(lr=learning_rate)\n","    callbacks=[EarlyStopping(patience=2, monitor='val_loss')]\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[categorical_accuracy])\n","    print(\"model built!\")\n","    return model"],"metadata":{"id":"4cw0ayUlGprH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Once we have the models define, we initialize them. We also define a learning rate and the amount of units in the model."],"metadata":{"id":"P8PGwgrVG0Dw"}},{"cell_type":"code","source":["units = 256 # units in the model\n","learning_rate = 0.001 #learning rate"],"metadata":{"id":"1M3-3P-WHxXr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Initialize models:"],"metadata":{"id":"revQLuJLHvAj"}},{"cell_type":"code","source":["# RNN\n","md_rnn = rnn_model(seq_length, vocab_size)\n","md_rnn.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S_oGUN6drHM-","executionInfo":{"status":"ok","timestamp":1655237769025,"user_tz":-120,"elapsed":1896,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"outputId":"583ec869-04a3-4088-ed0a-6d039b1e4e2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Build RNN model.\n","model built!\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," simple_rnn (SimpleRNN)      (None, 256)               534784    \n","                                                                 \n"," dropout (Dropout)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 1832)              470824    \n","                                                                 \n"," activation (Activation)     (None, 1832)              0         \n","                                                                 \n","=================================================================\n","Total params: 1,005,608\n","Trainable params: 1,005,608\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["# LSTM\n","md_lstm = lstm_model(seq_length, vocab_size)\n","md_lstm.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r1RZ0OGaHzaP","executionInfo":{"status":"ok","timestamp":1655237772261,"user_tz":-120,"elapsed":664,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"outputId":"4ec6a149-b31c-47ad-afec-edc736c73064"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Build LSTM model.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","model built!\n","Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 256)               2139136   \n","                                                                 \n"," dropout_1 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1832)              470824    \n","                                                                 \n"," activation_1 (Activation)   (None, 1832)              0         \n","                                                                 \n","=================================================================\n","Total params: 2,609,960\n","Trainable params: 2,609,960\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["# Bidirectional LSTM\n","md_bilstm = bidirectional_lstm_model(seq_length, vocab_size)\n","md_bilstm.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4LT97jUlH2_C","executionInfo":{"status":"ok","timestamp":1655237782087,"user_tz":-120,"elapsed":372,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"outputId":"4371515a-aac3-4a65-f3a3-e741bc3924b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Build LSTM model.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","model built!\n","Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," bidirectional (Bidirectiona  (None, 512)              4278272   \n"," l)                                                              \n","                                                                 \n"," dropout_2 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 1832)              939816    \n","                                                                 \n"," activation_2 (Activation)   (None, 1832)              0         \n","                                                                 \n","=================================================================\n","Total params: 5,218,088\n","Trainable params: 5,218,088\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"markdown","source":["## Training the Model\n","\n","**DO NOT RUN IF NOT NECESSARY**\n","\n","**The training of the models can take up to an hour, and previously trained models (same data) can be loaded in the next section.**"],"metadata":{"id":"6TLjp1587FjY"}},{"cell_type":"code","source":["batch_size = 32 # minibatch size\n","num_epochs = 50 # number of epochs"],"metadata":{"id":"2BDRtgOwHzkJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train RNN with the prepared data:"],"metadata":{"id":"6M7ycid2t3uy"}},{"cell_type":"code","source":["# train the RNN model\n","history = md_rnn.fit(X, y,\n","                 batch_size=batch_size,\n","                 shuffle=True,\n","                 epochs=num_epochs,\n","                 validation_split=0.1)\n","\n","# save the model\n","md_rnn.save(results_path + 'my_model_generate_sentences_rnn.h5')"],"metadata":{"id":"7bafoFIEtrC0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train LSTM with the prepared data:"],"metadata":{"id":"KLthD6O_t_Yb"}},{"cell_type":"code","source":["# train the LSTM model\n","history = md_lstm.fit(X, y,\n","                 batch_size=batch_size,\n","                 shuffle=True,\n","                 epochs=num_epochs,\n","                 validation_split=0.1)\n","\n","# save the model\n","md_lstm.save(results_path + 'my_model_generate_sentences_lstm.h5')"],"metadata":{"id":"cBzS2EA0t-r4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train BiLSTM with the prepared data:"],"metadata":{"id":"ios5NtQut-Qh"}},{"cell_type":"code","source":["# train the Biderectional LSTM model\n","history = md_bilstm.fit(X, y,\n","                 batch_size=batch_size,\n","                 shuffle=True,\n","                 epochs=num_epochs,\n","                 validation_split=0.1)\n","\n","# save the model\n","md_bilstm.save(results_path + 'my_model_generate_sentences_bilstm.h5')"],"metadata":{"id":"U2TMRa_dt992"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Upload Generated Data"],"metadata":{"id":"fTM8aDzT8ftC"}},{"cell_type":"markdown","source":["To upload a previously generated dictionary:"],"metadata":{"id":"qfAbGSnIlFjC"}},{"cell_type":"code","source":["# load vocabulary\n","print(\"loading vocabulary...\")\n","vocab_file = os.path.join(results_path, \"vocab_file.pkl\")\n","\n","with open(os.path.join(results_path, 'vocab_file.pkl'), 'rb') as f:\n","        words, vocab, vocabulary_inv = cPickle.load(f)\n","\n","vocab_size = len(words)"],"metadata":{"id":"Wr7FAoomH2D8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0027ef07-4fb7-4e83-893c-63df92652ce0","executionInfo":{"status":"ok","timestamp":1655237813945,"user_tz":-120,"elapsed":258,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading vocabulary...\n"]}]},{"cell_type":"markdown","source":["To load a trained model:"],"metadata":{"id":"NAsExMPamJv-"}},{"cell_type":"code","source":["from keras.models import load_model\n","\n","# load the RNN model\n","print(\"loading RNN model...\")\n","model_rnn = load_model(results_path + 'my_model_generate_sentences_rnn.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5-i3obPCmPL-","executionInfo":{"status":"ok","timestamp":1655237818604,"user_tz":-120,"elapsed":312,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"outputId":"8dc1cc43-d50a-4b12-e2a1-27cdbc76f539"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading RNN model...\n"]}]},{"cell_type":"code","source":["# load the LSTM model\n","print(\"loading LSTM model...\")\n","model_lstm = load_model(results_path + 'my_model_generate_sentences_lstm.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2m_beXOQxPtx","executionInfo":{"status":"ok","timestamp":1655237822092,"user_tz":-120,"elapsed":456,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"outputId":"c027f58d-bfa0-419b-8989-204d599af19a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading LSTM model...\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}]},{"cell_type":"code","source":["# load the BiLSTM model\n","print(\"loading BiLSTM model...\")\n","model_bilstm = load_model(results_path + 'my_model_generate_sentences_bilstm.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rp-3lC4Jm7_u","executionInfo":{"status":"ok","timestamp":1655237824341,"user_tz":-120,"elapsed":286,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"outputId":"88263862-29f1-44b0-a643-2a951fa54b3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading BiLSTM model...\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}]},{"cell_type":"markdown","source":["## Lyrics Generation\n","Define functions to generate lyrics, given a model, a length and a seed sentence."],"metadata":{"id":"9oHA2APF8sBN"}},{"cell_type":"code","source":["def sample(preds, temperature=1.0):\n","    # helper function to sample an index from a probability array\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)"],"metadata":{"id":"8qT9RjAzH4AN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_lyrics(model, words_to_generate, seed):\n","  # initiate sentences\n","  generated = ''\n","  sentence = []\n","  seq_length = 30\n","\n","  # we shate the seed accordingly to the neural netwrok needs:\n","  for i in range(seq_length):\n","      sentence.append(\"oh\")\n","\n","  seed = seed_sentences.split()\n","\n","  for i in range(len(seed)):\n","      sentence[seq_length-i-1]=seed[len(seed)-i-1]\n","\n","  generated += ' '.join(sentence)\n","\n","  #then, we generate the text\n","  for i in range(words_number):\n","      # create the vector\n","      x = np.zeros((1, seq_length, vocab_size))\n","      for t, word in enumerate(sentence):\n","        x[0, t, vocab[word]] = 1.\n","\n","      # calculate next word\n","      preds = model.predict(x, verbose=0)[0]\n","      next_index = sample(preds, 0.33)\n","      next_word = vocabulary_inv[next_index]\n","\n","      # add the next word to the text\n","      generated += \" \" + next_word\n","      # shift the sentence by one, and and the next word at its end\n","      sentence = sentence[1:] + [next_word]\n","\n","  # print the whole text\n","  return generated\n","  #print('\\n' + generated)"],"metadata":{"id":"5UFN7pqpH-nv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Generate Lyrics"],"metadata":{"id":"m1LVYMj8zVzr"}},{"cell_type":"code","source":["words_number = 200 # number of words to generate\n","\n","# seed sentence to start the generating.\n","seed_sentences = '''do you call her , almost say my name ? 'cause let 's say , we kinda do sound the same i hate to think that i was just your''' "],"metadata":{"id":"1iCVjmW_nvBY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Generate RNN:"],"metadata":{"id":"SKlL1W3S3ROp"}},{"cell_type":"code","source":["# generate from RNN model\n","rnn_gen_lyrics = generate_lyrics(model_rnn, words_number, seed_sentences)\n","print('\\n RNN\\n', rnn_gen_lyrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b998FHrEzeor","executionInfo":{"status":"ok","timestamp":1655237877803,"user_tz":-120,"elapsed":10061,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"outputId":"bf0d63d9-decb-4874-9810-d5170b14dfb1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n","  after removing the cwd from sys.path.\n"]},{"output_type":"stream","name":"stdout","text":["\n"," RNN\n"," do you call her , almost say my name ? 'cause let 's say , we kinda do sound the same i hate to think that i was just your  \n"," but i am the city  \n"," you let me be  \n","  \n"," somewhere in the middle of the never ending noise  \n"," there is a constant steady rhythm of a heart that beats  \n","  \n"," somewhere in the crowd  \n"," the first , you do  \n"," i 'm not a coward  \n"," oh no , i 'll be strong  \n"," one chance in a lifetime  \n"," yes i will take it , it ca n't go wrong  \n","  \n"," i 've been waiting for you  \n"," oh , i 'm riding higher than the sky and there is fire in every kiss  \n"," kisses of fire  \n"," kisses of fire  \n","  \n"," kisses of fire , burning , burning  \n"," i 'm at the point of no returning  \n"," kisses of fire , sweet devotions  \n"," caught in a landslide of emotions  \n"," i 've had my share of love affairs but they were nothing compared to this  \n"," oh , i 've been waiting for you  \n"," oh , i 've been waiting for you  \n"," oh , i 'm riding higher than the sky and there is nothing we can do  \n"," knowing me , knowing you ( ah - haa\n"]}]},{"cell_type":"markdown","source":["Generate LSTM:"],"metadata":{"id":"ryNyFJ6N3Yzc"}},{"cell_type":"code","source":["# generate from LSTM model\n","lstm_gen_lyrics = generate_lyrics(model_lstm, words_number, seed_sentences)\n","print('\\n LSTM\\n', lstm_gen_lyrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tU94GHqxziFw","executionInfo":{"status":"ok","timestamp":1655237918467,"user_tz":-120,"elapsed":9352,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"outputId":"dd9f54a1-8b60-489f-de45-8a7f4e947bf7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n","  after removing the cwd from sys.path.\n"]},{"output_type":"stream","name":"stdout","text":["\n"," LSTM\n"," do you call her , almost say my name ? 'cause let 's say , we kinda do sound the same i hate to think that i was just your  \n"," and i know what he 's gon na sing you make it all gon na sing it all comes back to me break  \n"," but who of the morning without you  \n","  \n"," would  \n"," to see you little longer , yeah  \n"," i can see that you must be our  \n"," to just a dream  \n"," we were always has to love for me  \n"," he 's too on  \n"," just a bell ring  \n"," one more the and we can hear the night  \n"," touch my my life is so sad ,  \n"," i 've been waiting for a night  \n"," i 'm not a movie  \n"," you know i was n't know what a mean  \n"," when you 're all alone  \n"," so dance while the music still goes on  \n"," it 's a crying of your mind  \n"," 'cause it 's gon na make it )  \n"," but i can imagine the night i want to be  \n","  \n"," i 'm gon na sing it my love song , gon na bring you some light  \n"," gon na make you feel happy every day of your life  \n"," gon na sing you my love song , gon\n"]}]},{"cell_type":"markdown","source":["Generate Bidirectional LSTM:"],"metadata":{"id":"7LMw2Mi_3b0n"}},{"cell_type":"code","source":["# generate from BiLSTM model\n","bilstm_gen_lyrics = generate_lyrics(model_bilstm, words_number, seed_sentences)\n","print('\\n BiLSTM\\n', bilstm_gen_lyrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4eC6CitSzkvv","executionInfo":{"status":"ok","timestamp":1655237934100,"user_tz":-120,"elapsed":9838,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"outputId":"418965e9-ef3d-4473-99cb-5336f9c85b16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n","  after removing the cwd from sys.path.\n"]},{"output_type":"stream","name":"stdout","text":["\n"," BiLSTM\n"," do you call her , almost say my name ? 'cause let 's say , we kinda do sound the same i hate to think that i was just your love  \n"," ca n't deny it  \n"," 'cause it 's true  \n"," i do , i do , i do  \n","  \n"," i do , i do  \n","  \n"," oh , no hard feelings between you and me  \n"," if we ca n't make it  \n"," but just wait and see  \n","  \n"," so come on now lets try it  \n"," i love you , ca n't deny it  \n"," 'cause it 's true , i do , i do , i do , i do , i do  \n","  \n"," so love me or leave me  \n"," make your choice but believe me  \n"," i love you , i do , i do , i do , i do , i do  \n","  \n"," i ca n't conceal it , do n't you see ?  \n"," ca n't you feel it ?  \n"," do n't you too ?  \n"," i do , i do , i do , i do , i do  \n","  \n"," oh , i 've been dreaming through my lonely past  \n"," now i 've just made it  \n"," i found you at last  \n"," so come on  \n"," now you let 's try it  \n"," i love you  \n"," ca\n"]}]}]}