{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lyricsGenAll.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Lyrics Generation\n","**Veronica Bruno (230904), Cristina Galvez (230260) and Rafael Bardisa (231142)**\n","\n","In this notebook, we prepare a dataset containing the lyrics of many famous songs to feed different Deep Learning Models:\n","- RNN \n","- LSTM\n","- BiDirectional LSTM\n","\n","Once the model is trained, it is able to generate new song lyrics given a seed (an initial string of words) that will resemble the patterns the model will have learned during training."],"metadata":{"id":"VWgAenKe3XxV"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJ8fwjF9-d3o","outputId":"a47a8773-8066-45cf-86c5-84505d8bc1a4","executionInfo":{"status":"ok","timestamp":1655280961723,"user_tz":-120,"elapsed":119223,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# import Keras library\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Activation, Dropout\n","from keras.layers import LSTM, SimpleRNN, Input, Bidirectional\n","from keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping\n","from keras.metrics import categorical_accuracy\n","\n","# import spacy, and spacy french model\n","# spacy is used to work on text\n","import spacy\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","#import other libraries\n","import numpy as np\n","import pandas as pd\n","import random\n","import sys\n","import os\n","import time\n","import codecs\n","import collections\n","from six.moves import cPickle\n","\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","data_path = '/content/drive/Shareddrives/Deep Learning/DeepLearning_2022/Final Project/Data/'\n","results_path = '/content/drive/Shareddrives/Deep Learning/DeepLearning_2022/Final Project/Results/'\n","\n","df = pd.read_csv(data_path + 'songdata.csv')"]},{"cell_type":"markdown","source":["### Data Preparation\n","\n","Prepare all data from the dataset *'songdata.csv'* to be used in the BiLSTM algorithm."],"metadata":{"id":"guB0c0ax4BmK"}},{"cell_type":"code","source":["# join all song lyrics from the dataset in a long string\n","data = ', '.join(df['text'])"],"metadata":{"id":"Gt1m167vJeTI","executionInfo":{"status":"ok","timestamp":1655280961724,"user_tz":-120,"elapsed":14,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# function to create a wordlist\n","def create_wordlist(doc):\n","    wl = []\n","    for word in doc:\n","        if word.text not in (\"\\n\",\"\\n\\n\",'\\u2009','\\xa0'):\n","            wl.append(word.text.lower())\n","    return wl"],"metadata":{"id":"F89hFuE8OSeb","executionInfo":{"status":"ok","timestamp":1655280961724,"user_tz":-120,"elapsed":13,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# create array of words (in order)\n","wordlist = []\n","word_limit = 100000 # define amount of words used (limited by RAM memory)\n","\n","doc = nlp(data[0:word_limit])\n","wl = create_wordlist(doc)\n","wordlist = wordlist + wl"],"metadata":{"id":"QbyhvtApHfIY","executionInfo":{"status":"ok","timestamp":1655280964373,"user_tz":-120,"elapsed":2661,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# count the number of words\n","word_counts = collections.Counter(wordlist)\n","\n","# Mapping from index to word : that's the vocabulary\n","vocabulary_inv = [x[0] for x in word_counts.most_common()]\n","vocabulary_inv = list(sorted(vocabulary_inv))\n","\n","# Mapping from word to index\n","vocab = {x: i for i, x in enumerate(vocabulary_inv)}\n","words = [x[0] for x in word_counts.most_common()]\n","\n","# size of the vocabulary\n","vocab_size = len(words)\n","print(\"Vocabulary size:\", vocab_size)\n","\n","# save the words and vocabulary\n","with open(results_path + \"vocab_file.pkl\", 'w+b') as f:\n","    cPickle.dump((words, vocab, vocabulary_inv), f)"],"metadata":{"id":"tBZO0DiCHm9f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8d22e913-0cac-4e4d-8e6a-61b52b77d8e8","executionInfo":{"status":"ok","timestamp":1655280965249,"user_tz":-120,"elapsed":545,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary size: 1832\n"]}]},{"cell_type":"code","source":["# create sequences of fixed length\n","sequences = []\n","next_words = []\n","seq_length = 30  # define sequence length\n","sequences_step = 1\n","\n","for i in range(0, len(wordlist) - seq_length, sequences_step):\n","    sequences.append(wordlist[i: i + seq_length])\n","    next_words.append(wordlist[i + seq_length])\n","\n","print('Number of sequences:', len(sequences))"],"metadata":{"id":"t5aEkfx6HpQC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f03e5eb4-6822-4c99-81a0-7f625823e394","executionInfo":{"status":"ok","timestamp":1655280965252,"user_tz":-120,"elapsed":7,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of sequences: 24326\n"]}]},{"cell_type":"code","source":["# define data as matrices with 0s and 1s\n","X = np.zeros((len(sequences), seq_length, vocab_size), dtype=np.bool)\n","y = np.zeros((len(sequences), vocab_size), dtype=np.bool)\n","for i, sentence in enumerate(sequences):\n","    for t, word in enumerate(sentence):\n","        X[i, t, vocab[word]] = 1\n","    y[i, vocab[next_words[i]]] = 1"],"metadata":{"id":"8S_gvIAXHr0c","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7a0fae96-6236-4205-f0b7-21c750aaecef","executionInfo":{"status":"ok","timestamp":1655280965951,"user_tz":-120,"elapsed":705,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]}]},{"cell_type":"markdown","source":["## Model Definition"],"metadata":{"id":"fEButMW36NqM"}},{"cell_type":"markdown","source":["The first model we are going to define will be the **RNN** model:"],"metadata":{"id":"3Rr_lAbmF8fE"}},{"cell_type":"code","source":["def rnn_model(seq_length, vocab_size):\n","    print('Build RNN model.')\n","    model = Sequential()\n","    model.add(SimpleRNN(units, activation=\"relu\",input_shape=(seq_length, vocab_size))) # add RNN layer\n","    model.add(Dropout(0.6))\n","    model.add(Dense(vocab_size))\n","    model.add(Activation('softmax'))\n","    \n","    optimizer = Adam(lr=learning_rate)\n","    callbacks=[EarlyStopping(patience=2, monitor='val_loss')]\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[categorical_accuracy])\n","    print(\"model built!\")\n","    return model"],"metadata":{"id":"G5MecYPwqlh7","executionInfo":{"status":"ok","timestamp":1655280965952,"user_tz":-120,"elapsed":11,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["The following is the **LSTM** model:"],"metadata":{"id":"jNvar8OhGCIX"}},{"cell_type":"code","source":["def lstm_model(seq_length, vocab_size):\n","    print('Build LSTM model.')\n","    model = Sequential()\n","    model.add(LSTM(units, activation=\"relu\",input_shape=(seq_length, vocab_size))) # add LSTM layer\n","    model.add(Dropout(0.6))\n","    model.add(Dense(vocab_size))\n","    model.add(Activation('softmax'))\n","    \n","    optimizer = Adam(lr=learning_rate)\n","    callbacks=[EarlyStopping(patience=2, monitor='val_loss')]\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[categorical_accuracy])\n","    print(\"model built!\")\n","    return model"],"metadata":{"id":"GeyDjz8vHuMU","executionInfo":{"status":"ok","timestamp":1655280965953,"user_tz":-120,"elapsed":11,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["The following function defines a **Bidirectional LSTM** model, which uses two LSTM models (one in each direction) so that both directions of propagation are taken into account."],"metadata":{"id":"s-5DUwuLGIJ8"}},{"cell_type":"code","source":["def bidirectional_lstm_model(seq_length, vocab_size):\n","    print('Build LSTM model.')\n","    model = Sequential()\n","    model.add(Bidirectional(LSTM(units, activation=\"relu\"),input_shape=(seq_length, vocab_size))) # add BiLSTM layer\n","    model.add(Dropout(0.6))\n","    model.add(Dense(vocab_size))\n","    model.add(Activation('softmax'))\n","    \n","    optimizer = Adam(lr=learning_rate)\n","    callbacks=[EarlyStopping(patience=2, monitor='val_loss')]\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[categorical_accuracy])\n","    print(\"model built!\")\n","    return model"],"metadata":{"id":"4cw0ayUlGprH","executionInfo":{"status":"ok","timestamp":1655280965953,"user_tz":-120,"elapsed":11,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Once we have the models define, we initialize them. We also define a learning rate and the amount of units in the model."],"metadata":{"id":"P8PGwgrVG0Dw"}},{"cell_type":"code","source":["units = 256 # units in the model\n","learning_rate = 0.001 #learning rate"],"metadata":{"id":"1M3-3P-WHxXr","executionInfo":{"status":"ok","timestamp":1655280965954,"user_tz":-120,"elapsed":11,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["Initialize models:"],"metadata":{"id":"revQLuJLHvAj"}},{"cell_type":"code","source":["# RNN\n","md_rnn = rnn_model(seq_length, vocab_size)\n","md_rnn.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S_oGUN6drHM-","executionInfo":{"status":"ok","timestamp":1655280969628,"user_tz":-120,"elapsed":3684,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"outputId":"b13162bb-62d2-4ff8-9c0c-bd7ab5b0fcb2"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Build RNN model.\n","model built!\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," simple_rnn (SimpleRNN)      (None, 256)               534784    \n","                                                                 \n"," dropout (Dropout)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 1832)              470824    \n","                                                                 \n"," activation (Activation)     (None, 1832)              0         \n","                                                                 \n","=================================================================\n","Total params: 1,005,608\n","Trainable params: 1,005,608\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["# LSTM\n","md_lstm = lstm_model(seq_length, vocab_size)\n","md_lstm.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r1RZ0OGaHzaP","executionInfo":{"status":"ok","timestamp":1655280970039,"user_tz":-120,"elapsed":422,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"outputId":"41ec906d-d8cb-4d6e-e4f8-55285c070549"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Build LSTM model.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","model built!\n","Model: \"sequential_1\"\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 256)               2139136   \n","                                                                 \n"," dropout_1 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1832)              470824    \n","                                                                 \n"," activation_1 (Activation)   (None, 1832)              0         \n","                                                                 \n","=================================================================\n","Total params: 2,609,960\n","Trainable params: 2,609,960\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Bidirectional LSTM\n","md_bilstm = bidirectional_lstm_model(seq_length, vocab_size)\n","md_bilstm.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4LT97jUlH2_C","executionInfo":{"status":"ok","timestamp":1655280970040,"user_tz":-120,"elapsed":33,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"outputId":"3c17fffe-6c6e-4d95-82a5-99dc931d0b79"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Build LSTM model.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","model built!\n","Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," bidirectional (Bidirectiona  (None, 512)              4278272   \n"," l)                                                              \n","                                                                 \n"," dropout_2 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 1832)              939816    \n","                                                                 \n"," activation_2 (Activation)   (None, 1832)              0         \n","                                                                 \n","=================================================================\n","Total params: 5,218,088\n","Trainable params: 5,218,088\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"markdown","source":["## Training the Model\n","\n","**DO NOT RUN IF NOT NECESSARY**\n","\n","**The training of the models can take up to an hour, and previously trained models (same data) can be loaded in the next section.**"],"metadata":{"id":"6TLjp1587FjY"}},{"cell_type":"code","source":["batch_size = 32 # minibatch size\n","num_epochs = 25 # number of epochs"],"metadata":{"id":"2BDRtgOwHzkJ","executionInfo":{"status":"ok","timestamp":1655283676287,"user_tz":-120,"elapsed":420,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["Train RNN with the prepared data:"],"metadata":{"id":"6M7ycid2t3uy"}},{"cell_type":"code","source":["# train the RNN model\n","history = md_rnn.fit(X, y,\n","                 batch_size=batch_size,\n","                 shuffle=True,\n","                 epochs=num_epochs,\n","                 validation_split=0.1)\n","\n","# save the model\n","md_rnn.save(results_path + 'my_model_generate_sentences_rnn.h5')"],"metadata":{"id":"7bafoFIEtrC0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train LSTM with the prepared data:"],"metadata":{"id":"KLthD6O_t_Yb"}},{"cell_type":"code","source":["# train the LSTM model\n","history = md_lstm.fit(X, y,\n","                 batch_size=batch_size,\n","                 shuffle=True,\n","                 epochs=num_epochs,\n","                 validation_split=0.1)\n","\n","# save the model\n","md_lstm.save(results_path + 'my_model_generate_sentences_lstm.h5')"],"metadata":{"id":"cBzS2EA0t-r4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train BiLSTM with the prepared data:"],"metadata":{"id":"ios5NtQut-Qh"}},{"cell_type":"code","source":["# train the Biderectional LSTM model\n","history = md_bilstm.fit(X, y,\n","                 batch_size=batch_size,\n","                 shuffle=True,\n","                 epochs=num_epochs,\n","                 validation_split=0.1)\n","\n","# save the model\n","md_bilstm.save(results_path + 'my_model_generate_sentences_bilstm.h5')"],"metadata":{"id":"U2TMRa_dt992"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Upload Generated Data"],"metadata":{"id":"fTM8aDzT8ftC"}},{"cell_type":"markdown","source":["To upload a previously generated dictionary:"],"metadata":{"id":"qfAbGSnIlFjC"}},{"cell_type":"code","source":["# load vocabulary\n","print(\"loading vocabulary...\")\n","vocab_file = os.path.join(results_path, \"vocab_file.pkl\")\n","\n","with open(os.path.join(results_path, 'vocab_file.pkl'), 'rb') as f:\n","        words, vocab, vocabulary_inv = cPickle.load(f)\n","\n","vocab_size = len(words)"],"metadata":{"id":"Wr7FAoomH2D8","executionInfo":{"status":"ok","timestamp":1655283276838,"user_tz":-120,"elapsed":348,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f2b116d2-3fde-40a5-bdca-cc9997360888"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["loading vocabulary...\n"]}]},{"cell_type":"markdown","source":["To load a trained model:"],"metadata":{"id":"NAsExMPamJv-"}},{"cell_type":"code","source":["from keras.models import load_model\n","\n","file_to_load = 'my_model_generate_sentences_rnn_10.h5' # model trained with 10 epochs\n","# can also try my_model_generate_sentences_rnn_50.h5 (with 50 epochs)\n","\n","# load the RNN model\n","print(\"loading RNN model...\")\n","model_rnn = load_model(results_path + file_to_load)"],"metadata":{"id":"5-i3obPCmPL-","executionInfo":{"status":"ok","timestamp":1655285768781,"user_tz":-120,"elapsed":739,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5965efe2-0cc4-4bf6-8206-be60ac523e32"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["loading RNN model...\n"]}]},{"cell_type":"code","source":["file_to_load = 'my_model_generate_sentences_lstm_10.h5' # model trained with 10 epochs\n","# can also try my_model_generate_sentences_lstm_50.h5 (with 50 epochs)\n","\n","# load the LSTM model\n","print(\"loading LSTM model...\")\n","model_lstm = load_model(results_path + file_to_load)"],"metadata":{"id":"2m_beXOQxPtx","executionInfo":{"status":"ok","timestamp":1655285772766,"user_tz":-120,"elapsed":518,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2d9104a4-4be8-4ea9-cbea-cd843ee21994"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["loading LSTM model...\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}]},{"cell_type":"code","source":["file_to_load = 'my_model_generate_sentences_bilstm_25.h5' # model trained with 25 epochs\n","# can also try my_model_generate_sentences_bilstm_50.h5 (with 50 epochs)\n","\n","# load the BiLSTM model\n","print(\"loading BiLSTM model...\")\n","model_bilstm = load_model(results_path + file_to_load)"],"metadata":{"id":"rp-3lC4Jm7_u","executionInfo":{"status":"ok","timestamp":1655285774695,"user_tz":-120,"elapsed":481,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1268165a-a328-4500-a3a1-35d0f984c381"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["loading BiLSTM model...\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}]},{"cell_type":"markdown","source":["## Lyrics Generation\n","Define functions to generate lyrics, given a model, a length and a seed sentence."],"metadata":{"id":"9oHA2APF8sBN"}},{"cell_type":"code","source":["def sample(preds, temperature=1.0):\n","    # helper function to sample an index from a probability array\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)"],"metadata":{"id":"8qT9RjAzH4AN","executionInfo":{"status":"ok","timestamp":1655283292239,"user_tz":-120,"elapsed":350,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def generate_lyrics(model, words_to_generate, seed):\n","  # initiate sentences\n","  generated = ''\n","  sentence = []\n","  seq_length = 30\n","\n","  # we shate the seed accordingly to the neural netwrok needs:\n","  for i in range(seq_length):\n","      sentence.append(\"oh\")\n","\n","  seed = seed_sentences.split()\n","\n","  for i in range(len(seed)):\n","      sentence[seq_length-i-1]=seed[len(seed)-i-1]\n","\n","  generated += ' '.join(sentence)\n","\n","  #then, we generate the text\n","  for i in range(words_number):\n","      # create the vector\n","      x = np.zeros((1, seq_length, vocab_size))\n","      for t, word in enumerate(sentence):\n","        x[0, t, vocab[word]] = 1.\n","\n","      # calculate next word\n","      preds = model.predict(x, verbose=0)[0]\n","      next_index = sample(preds, 0.33)\n","      next_word = vocabulary_inv[next_index]\n","\n","      # add the next word to the text\n","      generated += \" \" + next_word\n","      # shift the sentence by one, and and the next word at its end\n","      sentence = sentence[1:] + [next_word]\n","\n","  # print the whole text\n","  return generated\n","  #print('\\n' + generated)"],"metadata":{"id":"5UFN7pqpH-nv","executionInfo":{"status":"ok","timestamp":1655283293985,"user_tz":-120,"elapsed":456,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["#### Generate Lyrics"],"metadata":{"id":"m1LVYMj8zVzr"}},{"cell_type":"code","source":["words_number = 200 # number of words to generate\n","\n","# seed sentence to start the generating.\n","seed_sentences = '''do you want her , almost every day ? 'cause let 's say , we kinda do look the same i hate to think that every time''' "],"metadata":{"id":"1iCVjmW_nvBY","executionInfo":{"status":"ok","timestamp":1655283355352,"user_tz":-120,"elapsed":304,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["Generate RNN:"],"metadata":{"id":"SKlL1W3S3ROp"}},{"cell_type":"code","source":["# generate from RNN model\n","rnn_gen_lyrics = generate_lyrics(model_rnn, words_number, seed_sentences)\n","print('\\n RNN\\n', rnn_gen_lyrics)"],"metadata":{"id":"b998FHrEzeor","executionInfo":{"status":"ok","timestamp":1655284374365,"user_tz":-120,"elapsed":9546,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cd9e0a10-d08f-4ae1-ba1c-e60658b6e9b9"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," RNN\n"," oh oh oh do you want her , almost every day ? 'cause let 's say , we kinda do look the same i hate to think that every time  \n"," i 'm always givin ' a little more  \n"," i 've been brokenhearted  \n"," you 're out  \n"," we 're through  \n"," and i 'm blue  \n"," and i come you 're my love , my life  \n"," but the sun is a marionette  \n"," just a girl , you 're all  \n"," and i 've been you  \n"," and my life , baby , you 're , i have to go  \n"," and i do n't want to lose my life  \n"," but i 've got all my memories , those were my happiest days  \n","  \n"," where i 'm your eyes , i ca n't go  \n"," in the gloom  \n"," like an angel passing through my room  \n","  \n"," i 'm going in  \n"," and i 'm your eyes  \n"," i 'm the city , you 're me  \n"," and you 'll be you can to be  \n"," where the gloom  \n"," like an angel passing through my room  \n","  \n"," i know that you 're not the morning , i 'm not the point of no returning  \n"," but i 'm a marionette , baby , i do , i do , i do , i do ,\n"]}]},{"cell_type":"markdown","source":["Generate LSTM:"],"metadata":{"id":"ryNyFJ6N3Yzc"}},{"cell_type":"code","source":["# generate from LSTM model\n","lstm_gen_lyrics = generate_lyrics(model_lstm, words_number, seed_sentences)\n","print('\\n LSTM\\n', lstm_gen_lyrics)"],"metadata":{"id":"tU94GHqxziFw","executionInfo":{"status":"ok","timestamp":1655284393317,"user_tz":-120,"elapsed":9292,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c6b958ad-97cf-45ce-b612-fb2b2e44c363"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," LSTM\n"," oh oh oh do you want her , almost every day ? 'cause let 's say , we kinda do look the same i hate to think that every time  \n"," for you  \n"," so on the i  \n"," and the when you see the the the thought you 're me  \n"," and the and me  \n"," you you 're me  \n"," and i know that you 're so bad  \n"," so and i 'm you and you , you me  \n"," and me you 're me  \n"," and you me me , you and me you me and i me  \n"," now i 'm the the the feeling  \n"," you 're take me  \n","  \n"," my and i 'm ?  \n"," i 'm a n't to to , to me  \n"," take it 's a crazy  \n"," and i have  \n"," my got they all  \n"," we and 've and i the blind you  \n"," and me the old but the him , you the the the way  \n"," you 're the by  \n"," so  \n"," and you 're you still the you  \n"," in the on the the the man of the every day  \n"," so the man in the a man in the middle , the middle , the in the middle , the middle , the middle , the middle , the middle , the 's\n"]}]},{"cell_type":"markdown","source":["Generate Bidirectional LSTM:"],"metadata":{"id":"7LMw2Mi_3b0n"}},{"cell_type":"code","source":["# generate from BiLSTM model\n","bilstm_gen_lyrics = generate_lyrics(model_bilstm, words_number, seed_sentences)\n","print('\\n BiLSTM\\n', bilstm_gen_lyrics)"],"metadata":{"id":"4eC6CitSzkvv","executionInfo":{"status":"ok","timestamp":1655283488161,"user_tz":-120,"elapsed":10160,"user":{"displayName":"CRISTINA GÁLVEZ","userId":"08139489486073325841"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7f2cce9b-fcbd-4429-aeeb-e6ccc91e9416"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n","  after removing the cwd from sys.path.\n"]},{"output_type":"stream","name":"stdout","text":["\n"," BiLSTM\n"," oh oh oh do you want her , almost every day ? 'cause let 's say , we kinda do look the same i hate to think that every time for the time  \n"," but everything is a new song  \n"," and when you 're so sad  \n"," and you 're so free  \n"," that 's the things that you be  \n","  \n"," just a notion  \n"," that 's just look at that guy  \n","  \n"," just a face that in all  \n"," but she would be  \n"," but just special  \n"," as long as good as new , thank god it 's true  \n"," darling , we were always meant to stay together  \n","  \n"," making somebody happy is a question of give and learn  \n"," you can see that my love is just like a face that like a living in  \n"," a dreamworld  \n","  \n"," just just like a girl  \n"," just not just like cinderella  \n"," nina , pretty ballerina , who would ever ever ever only way  \n"," just just like cinderella , just cinderella  \n"," but just just like cinderella , just like cinderella  \n"," nina , pretty ballerina , who would ever think she could be the way  \n"," this is the moment she just just like cinderella , just like cinderella  \n"," nina , pretty ballerina , who would ever think she could be this way\n"]}]}]}